# Example configuration for terraform-ingest with vector database embeddings
# This demonstrates how to enable semantic search with ChromaDB

repositories:
  # Example: AWS VPC Terraform module
  - url: https://github.com/terraform-aws-modules/terraform-aws-vpc
    name: terraform-aws-vpc
    branches:
      - master
    include_tags: true
    max_tags: 2
    path: .
    recursive: false
    exclude_paths: []

  # Example: AWS EC2 Terraform module
  - url: https://github.com/terraform-aws-modules/terraform-aws-ec2-instance
    name: terraform-aws-ec2
    branches: []
    include_tags: true
    max_tags: 1
    path: .
    exclude_paths:
      - "examples/*"
      - "test/*"

# Output directory for JSON summaries
output_dir: ./output

# Directory for cloning repositories
clone_dir: ./repos

# MCP (Model Context Protocol) service configuration
mcp:
  auto_ingest: true               # Enable automatic ingestion when MCP server starts
  ingest_on_startup: true         # Run ingestion immediately on startup  
  refresh_interval_hours: 6       # Auto-refresh every 6 hours (null to disable)
  config_file: config.yaml        # Configuration file to use for auto-ingestion

# Vector database embedding configuration
embedding:
  enabled: true                             # Enable embeddings
  strategy: chromadb-default                # Options: chromadb-default, openai, claude, sentence-transformers
  
  # ChromaDB configuration
  chromadb_path: ./chromadb                 # Path to ChromaDB storage
  collection_name: terraform_modules        # Collection name
  
  # What to embed
  include_description: true                 # Include module description
  include_readme: true                      # Include README content
  include_variables: true                   # Include variable definitions
  include_outputs: true                     # Include output definitions
  include_resource_types: true              # Include provider and module info
  
  # Hybrid search configuration
  enable_hybrid_search: true                # Enable hybrid vector + keyword search
  keyword_weight: 0.3                       # Weight for keyword search (0.0-1.0)
  vector_weight: 0.7                        # Weight for vector search (0.0-1.0)

# For OpenAI embeddings, uncomment and configure:
# embedding:
#   enabled: true
#   strategy: openai
#   openai_api_key: sk-...  # Or set OPENAI_API_KEY env var
#   openai_model: text-embedding-3-small
#   chromadb_path: ./chromadb
#   collection_name: terraform_modules

# For local sentence-transformers, uncomment and configure:
# embedding:
#   enabled: true
#   strategy: sentence-transformers
#   sentence_transformers_model: all-MiniLM-L6-v2
#   chromadb_path: ./chromadb
#   collection_name: terraform_modules
